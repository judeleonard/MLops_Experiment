{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A end-to-end MLOps pipeline using the following tools\n",
    "1. Prefect (workflow)\n",
    "2. MLFlow (experiment tracking)\n",
    "3. Seldon (Model serving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll simply be using scikit-learn and some common data processing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_data():\n",
    "    csv_url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "    # create list of column names\n",
    "    col_name = ['sepal_length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "    data = pd.read_csv(csv_url, names=col_name)\n",
    "    return data\n",
    "\n",
    "data = fetch_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Setting up the training and the evaluation metrics for the model in this case KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNearestClassifier model (leaf_size=5.000000, n_neighbors=6.000000):\n",
      "  Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(actual, pred, average=None):\n",
    "   # Precision = metrics.precision_score(actual, pred)\n",
    "    #F1_score = metrics.f1_score(actual, pred)\n",
    "    Accuracy = metrics.accuracy_score(actual, pred)\n",
    "    return Accuracy\n",
    "\n",
    "def train_model(data, leaf_size=5, n_neighbors=6):\n",
    "    train, test = train_test_split(data, test_size=30)\n",
    "   \n",
    "    # the predicted column is the class which will be dropped from the x-train values \n",
    "    train_x = train.drop([\"class\"], axis=1)\n",
    "    test_x = test.drop([\"class\"], axis=1)\n",
    "    train_y = train[[\"class\"]]\n",
    "    test_y = test[[\"class\"]]\n",
    "    \n",
    "    KNN_model = KNeighborsClassifier(leaf_size=leaf_size, n_neighbors=n_neighbors)\n",
    "    KNN_model.fit(train_x, train_y)\n",
    "    \n",
    "    predicted_classes = KNN_model.predict(test_x)\n",
    "    Accuracy = eval_metrics(test_y, predicted_classes)\n",
    "  #  Precision, F1_score, Accuracy = eval_metrics(test_y, predicted_classes)\n",
    "    \n",
    "     # Print out the accuracy metrics\n",
    "    print(\"KNearestClassifier model (leaf_size=%f, n_neighbors=%f):\" % (leaf_size, n_neighbors))\n",
    "  #  print(\"  Precision: %s\" % Precision)\n",
    "  #  print(\"  F1 Score: %s\" % F1_score)\n",
    "    print(\"  Accuracy: %s\" % Accuracy)\n",
    "    \n",
    "data = fetch_data()\n",
    "train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking with MLFlow\n",
    "The goal is to modify the training functions above to include tracking with MLFlow\n",
    "\n",
    "### Starting the MLFlow server\n",
    "In a terminal, run the following;  \n",
    "mlflow server  \n",
    "This should start the tracking server at http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "def train_model(data, mlflow_experiment_id, leaf_size=5, n_neighbors=6):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") #Localhost\n",
    "\n",
    "    train, test = train_test_split(data, test_size=30)\n",
    "\n",
    "    # The predicted column is \"class\" \n",
    "    train_x = train.drop([\"class\"], axis=1)\n",
    "    test_x = test.drop([\"class\"], axis=1)\n",
    "    train_y = train[[\"class\"]]\n",
    "    test_y = test[[\"class\"]]\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=mlflow_experiment_id):\n",
    "        KNN_model = KNeighborsClassifier(leaf_size=leaf_size, n_neighbors=n_neighbors)\n",
    "        KNN_model.fit(train_x, train_y)\n",
    "        predicted_classes = KNN_model.predict(test_x)\n",
    "        Accuracy = eval_metrics(test_y, predicted_classes)\n",
    "\n",
    "        print(\"KNearestClassifier model (leaf_size=%f, n_neighbors=%f):\" % (leaf_size, n_neighbors))\n",
    "        print(\"  Accuracy: %s\" % Accuracy)\n",
    "\n",
    "        mlflow.log_param(\"leaf_size\", leaf_size)\n",
    "        mlflow.log_param(\"n_neighbors\", n_neighbors)\n",
    "        mlflow.log_metric(\"Accuracy\", Accuracy)\n",
    "\n",
    "        mlflow.sklearn.log_model(KNN_model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note some important changes in the new train_model method above:\n",
    "\n",
    "1. The new parameter, mlflow_experiment_id, which lets us associated runs with a specific experiment\n",
    "2. We set the URI of our MLFlow instance.\n",
    "3. The new with block that starts a run on MLFlow\n",
    "4. The mlflow.log_metric calls which post our results back to MLFlow\n",
    "5. The log_model call at the end which saves the entire trained model to MLFlow. This is useful to ensure we never lose a model that we previously trained.\n",
    "\n",
    "#### Now we train the model the model on new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNearestClassifier model (leaf_size=10.000000, n_neighbors=10.000000):\n",
      "  Accuracy: 0.9\n",
      "KNearestClassifier model (leaf_size=5.000000, n_neighbors=6.000000):\n",
      "  Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "train_model(data, mlflow_experiment_id=0, leaf_size=10, n_neighbors=10)\n",
    "train_model(data, mlflow_experiment_id=0, leaf_size=5, n_neighbors=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### We set up Prefect to fetch the data and retrain the model every two minutes for demonstration purposes\n",
    "\n",
    "First, let's modify the fetch_data and train_model functions by adding the @task decorator to each. This will indicate to Prefect that these are units of work which need to be run, and which may depend on each other in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, Flow, Parameter, Client\n",
    "from prefect.run_configs import LocalRun\n",
    "from prefect.schedules import IntervalSchedule\n",
    "import requests\n",
    "from datetime import timedelta\n",
    "\n",
    "@task\n",
    "def fetch_data():\n",
    "    csv_url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "    \n",
    "    # create list of column names\n",
    "    col_name = ['sepal_length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "    data = pd.read_csv(csv_url, names=col_name)\n",
    "    return data\n",
    "\n",
    "@task\n",
    "def train_model(data, mlflow_experiment_id, leaf_size=5, n_neighbors=6):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") #Localhost\n",
    "\n",
    "    train, test = train_test_split(data, test_size=30)\n",
    "\n",
    "    # The predicted column is \"class\"\n",
    "    train_x = train.drop([\"class\"], axis=1)\n",
    "    test_x = test.drop([\"class\"], axis=1)\n",
    "    train_y = train[[\"class\"]]\n",
    "    test_y = test[[\"class\"]]\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=mlflow_experiment_id):\n",
    "        KNN_model = KNeighborsClassifier(leaf_size=leaf_size, n_neighbors=n_neighbors)\n",
    "        KNN_model.fit(train_x, train_y)\n",
    "        predicted_classes = KNN_model.predict(test_x)\n",
    "        Accuracy = eval_metrics(test_y, predicted_classes)\n",
    "        print(\"KNearestClassifier model (leaf_size=%f, n_neighbors=%f):\" % (leaf_size, n_neighbors))\n",
    "\n",
    "        mlflow.log_param(\"leaf_size\", leaf_size)\n",
    "        mlflow.log_param(\"n_neighbors\", n_neighbors)\n",
    "        mlflow.log_metric(\"Accuracy\", Accuracy)\n",
    "\n",
    "        mlflow.sklearn.log_model(KNN_model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefect flow\n",
    "\n",
    "Note that you'll need to setup your own prefect cloud account to view the prefect dashboard  \n",
    "You'll also need to login through the prefect CLI.\n",
    "Follow this tutorial to achieve the above steps;   \n",
    "https://docs.prefect.io/orchestration/getting-started/set-up.html#server-or-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow URL: https://cloud.prefect.io/judeleonard86-gmail-com-s-account/flow/208f3ed5-9f8e-41eb-b368-6adda02d9f0e\n",
      " └── ID: 606dbfb9-502f-413a-8565-98a83963c09f\n",
      " └── Project: Iris_Class_Prediction\n",
      " └── Labels: ['Jude']\n",
      "[2021-09-02 11:42:31,289] INFO - agent | Registering agent...\n",
      "[2021-09-02 11:42:31,831] INFO - agent | Registration successful!\n",
      "\n",
      " ____            __           _        _                    _\n",
      "|  _ \\ _ __ ___ / _| ___  ___| |_     / \\   __ _  ___ _ __ | |_\n",
      "| |_) | '__/ _ \\ |_ / _ \\/ __| __|   / _ \\ / _` |/ _ \\ '_ \\| __|\n",
      "|  __/| | |  __/  _|  __/ (__| |_   / ___ \\ (_| |  __/ | | | |_\n",
      "|_|   |_|  \\___|_|  \\___|\\___|\\__| /_/   \\_\\__, |\\___|_| |_|\\__|\n",
      "                                           |___/\n",
      "\n",
      "[2021-09-02 11:42:47,342] INFO - agent | Starting LocalAgent with labels ['Jude']\n",
      "[2021-09-02 11:42:47,342] INFO - agent | Agent documentation can be found at https://docs.prefect.io/orchestration/\n",
      "[2021-09-02 11:42:47,357] INFO - agent | Waiting for flow runs...\n",
      "[2021-09-02 11:44:49,097] INFO - agent | Deploying flow run fffef66f-1e06-4e27-b2b1-e702e14fd63d to execution environment...\n",
      "[2021-09-02 11:45:41,027] INFO - agent | Completed deployment of flow run fffef66f-1e06-4e27-b2b1-e702e14fd63d\n",
      "[2021-09-02 11:48:36,950] INFO - agent | Deploying flow run 78e8abea-e969-44a7-9400-9da8d66c2e8d to execution environment...\n",
      "[2021-09-02 11:48:37,776] INFO - agent | Completed deployment of flow run 78e8abea-e969-44a7-9400-9da8d66c2e8d\n",
      "[2021-09-02 11:49:30,145] INFO - agent | Deploying flow run 9e206caa-5a3f-44c1-89ad-693965e47489 to execution environment...\n",
      "[2021-09-02 11:49:30,161] INFO - agent | Deploying flow run 4c988a22-27a0-4fc5-b701-c8d1984a591c to execution environment...\n",
      "[2021-09-02 11:49:30,176] INFO - agent | Deploying flow run 39fd4c07-7ede-459c-9494-7261bddbfde8 to execution environment...\n",
      "[2021-09-02 11:49:30,815] INFO - agent | Completed deployment of flow run 39fd4c07-7ede-459c-9494-7261bddbfde8\n",
      "[2021-09-02 11:49:30,821] INFO - agent | Completed deployment of flow run 4c988a22-27a0-4fc5-b701-c8d1984a591c\n",
      "[2021-09-02 11:49:30,844] INFO - agent | Completed deployment of flow run 9e206caa-5a3f-44c1-89ad-693965e47489\n",
      "[2021-09-02 11:50:54,432] INFO - agent | Deploying flow run 7c6d553f-7881-4e92-9d28-96d7e1d1631d to execution environment...\n",
      "[2021-09-02 11:50:55,178] INFO - agent | Completed deployment of flow run 7c6d553f-7881-4e92-9d28-96d7e1d1631d\n",
      "[2021-09-02 11:52:52,445] INFO - agent | Deploying flow run 4191e7fa-a93e-47cc-b3ff-9d3b5cc5f51f to execution environment...\n",
      "[2021-09-02 11:53:07,992] INFO - agent | Completed deployment of flow run 4191e7fa-a93e-47cc-b3ff-9d3b5cc5f51f\n",
      "[2021-09-02 11:54:22,150] INFO - agent | Deploying flow run 695093dc-58f8-4b05-9d7a-d253e2cb512f to execution environment...\n",
      "[2021-09-02 11:54:38,511] INFO - agent | Completed deployment of flow run 695093dc-58f8-4b05-9d7a-d253e2cb512f\n",
      "[2021-09-02 11:55:10,925] INFO - agent | Keyboard interrupt received! Shutting down...\n",
      "[2021-09-02 11:57:25,628] ERROR - agent | Exception encountered while deploying flow run 695093dc-58f8-4b05-9d7a-d253e2cb512f\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\util\\connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\util\\connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 976, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connection.py\", line 308, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connection.py\", line 167, in _new_conn\n",
      "    % (self.host, self.timeout),\n",
      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000020BE2D85A88>, 'Connection to api.prefect.io timed out. (connect timeout=15)')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\requests\\adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 765, in urlopen\n",
      "    **response_kw\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 765, in urlopen\n",
      "    **response_kw\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 765, in urlopen\n",
      "    **response_kw\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.prefect.io', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020BE2D85A88>, 'Connection to api.prefect.io timed out. (connect timeout=15)'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\agent\\agent.py\", line 398, in _deploy_flow_run\n",
      "    level=\"INFO\",\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\agent\\agent.py\", line 812, in _safe_write_run_log\n",
      "    level=level,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\client\\client.py\", line 1992, in write_run_logs\n",
      "    mutation, variables=dict(input=dict(logs=logs))\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\client\\client.py\", line 550, in graphql\n",
      "    retry_on_api_error=retry_on_api_error,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\client\\client.py\", line 454, in post\n",
      "    retry_on_api_error=retry_on_api_error,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\client\\client.py\", line 734, in _request\n",
      "    session=session, method=method, url=url, params=params, headers=headers\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\prefect\\client\\client.py\", line 602, in _send_request\n",
      "    timeout=prefect.context.config.cloud.request_timeout,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\requests\\sessions.py\", line 590, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\Pyspark\\lib\\site-packages\\requests\\adapters.py\", line 504, in send\n",
      "    raise ConnectTimeout(e, request=request)\n",
      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.prefect.io', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020BE2D85A88>, 'Connection to api.prefect.io timed out. (connect timeout=15)'))\n",
      "[2021-09-02 11:57:26,226] ERROR - agent | Updating flow run 695093dc-58f8-4b05-9d7a-d253e2cb512f state to Failed...\n",
      "[2021-09-02 11:57:44,677] ERROR - agent | Deployment of 695093dc-58f8-4b05-9d7a-d253e2cb512f aborted!\n"
     ]
    }
   ],
   "source": [
    "def create_prefect_flow():    \n",
    "    schedule = IntervalSchedule(interval=timedelta(minutes=2))\n",
    "\n",
    "    with Flow(\"iris-data-model\", schedule) as flow:\n",
    "        data = fetch_data()\n",
    "        train_model(data=data, mlflow_experiment_id=0, leaf_size=10, n_neighbors=10)\n",
    "\n",
    "    flow.register(project_name=\"Iris_Class_Prediction\")\n",
    "    flow.run_agent(token=\"lz80rpY0iqZhRg528KqATQ\")\n",
    "    \n",
    "create_prefect_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The error message is as a result of shutting down the runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's deploy the model to a seldon API\n",
    "\n",
    "We specify a list of dependencies and versions in a conda.yaml file. These will be saved with the model in MLFLow, and used by Seldon when running the model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
